{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare STree with different estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Uncomment the next cell if STree is not already installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Google Colab setup\n",
    "#\n",
    "#!pip install git+https://github.com/doctorado-ml/stree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from stree import Stree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.isfile('data/creditcard.csv'):\n",
    "    !wget --no-check-certificate --content-disposition http://nube.jccm.es/index.php/s/Zs7SYtZQJ3RQ2H2/download\n",
    "    !tar xzf creditcard.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-11-01 11:14:06\n"
     ]
    }
   ],
   "source": [
    "print(datetime.date.today(), time.strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset and normalize values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv('data/creditcard.csv')\n",
    "df.shape\n",
    "random_state = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fraud: 0.173% 492\nValid: 99.827% 284,315\n"
     ]
    }
   ],
   "source": [
    "print(\"Fraud: {0:.3f}% {1}\".format(df.Class[df.Class == 1].count()*100/df.shape[0], df.Class[df.Class == 1].count()))\n",
    "print(\"Valid: {0:.3f}% {1:,}\".format(df.Class[df.Class == 0].count()*100/df.shape[0], df.Class[df.Class == 0].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Amount\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "values = RobustScaler().fit_transform(df.Amount.values.reshape(-1, 1))\n",
    "df['Amount_Scaled'] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X shape: (284807, 29)\ny shape: (284807,)\n"
     ]
    }
   ],
   "source": [
    "# Remove unneeded features\n",
    "y = df.Class.values\n",
    "X = df.drop(['Class', 'Time', 'Amount'], axis=1).values\n",
    "print(f\"X shape: {X.shape}\\ny shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide dataset\n",
    "train_size = .7\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=train_size, shuffle=True, random_state=random_state, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Tree\n",
    "linear_tree = tree.DecisionTreeClassifier(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "random_forest = RandomForestClassifier(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stree\n",
    "stree = Stree(random_state=random_state, C=.01, max_iter=1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost\n",
    "adaboost = AdaBoostClassifier(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging\n",
    "bagging = BaggingClassifier(random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_model(name, model):\n",
    "    print(f\"************************** {name} **********************\")\n",
    "    now = time.time()\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    spent = time.time() - now\n",
    "    print(f\"Train Model {name} took: {spent:.4} seconds\")\n",
    "    predict = model.predict(Xtrain)\n",
    "    predictt = model.predict(Xtest)\n",
    "    print(f\"=========== {name} - Train {Xtrain.shape[0]:,} samples =============\",)\n",
    "    print(classification_report(ytrain, predict, digits=6))\n",
    "    print(f\"=========== {name} - Test {Xtest.shape[0]:,} samples =============\")\n",
    "    print(classification_report(ytest, predictt, digits=6))\n",
    "    print(\"Confusion Matrix in Train\")\n",
    "    print(confusion_matrix(ytrain, predict))\n",
    "    print(\"Confusion Matrix in Test\")\n",
    "    print(confusion_matrix(ytest, predictt))\n",
    "    return f1_score(ytest, predictt), spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "************************** Linear Tree **********************\n",
      "Train Model Linear Tree took: 15.14 seconds\n",
      "=========== Linear Tree - Train 199,364 samples =============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   1.000000  1.000000  1.000000    199020\n",
      "           1   1.000000  1.000000  1.000000       344\n",
      "\n",
      "    accuracy                       1.000000    199364\n",
      "   macro avg   1.000000  1.000000  1.000000    199364\n",
      "weighted avg   1.000000  1.000000  1.000000    199364\n",
      "\n",
      "=========== Linear Tree - Test 85,443 samples =============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.999578  0.999613  0.999596     85295\n",
      "           1   0.772414  0.756757  0.764505       148\n",
      "\n",
      "    accuracy                       0.999192     85443\n",
      "   macro avg   0.885996  0.878185  0.882050     85443\n",
      "weighted avg   0.999184  0.999192  0.999188     85443\n",
      "\n",
      "Confusion Matrix in Train\n",
      "[[199020      0]\n",
      " [     0    344]]\n",
      "Confusion Matrix in Test\n",
      "[[85262    33]\n",
      " [   36   112]]\n",
      "************************** Random Forest **********************\n",
      "Train Model Random Forest took: 181.1 seconds\n",
      "=========== Random Forest - Train 199,364 samples =============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   1.000000  1.000000  1.000000    199020\n",
      "           1   1.000000  1.000000  1.000000       344\n",
      "\n",
      "    accuracy                       1.000000    199364\n",
      "   macro avg   1.000000  1.000000  1.000000    199364\n",
      "weighted avg   1.000000  1.000000  1.000000    199364\n",
      "\n",
      "=========== Random Forest - Test 85,443 samples =============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.999660  0.999965  0.999812     85295\n",
      "           1   0.975410  0.804054  0.881481       148\n",
      "\n",
      "    accuracy                       0.999625     85443\n",
      "   macro avg   0.987535  0.902009  0.940647     85443\n",
      "weighted avg   0.999618  0.999625  0.999607     85443\n",
      "\n",
      "Confusion Matrix in Train\n",
      "[[199020      0]\n",
      " [     0    344]]\n",
      "Confusion Matrix in Test\n",
      "[[85292     3]\n",
      " [   29   119]]\n",
      "************************** Stree (SVM Tree) **********************\n",
      "Train Model Stree (SVM Tree) took: 36.6 seconds\n",
      "=========== Stree (SVM Tree) - Train 199,364 samples =============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.999623  0.999864  0.999744    199020\n",
      "           1   0.908784  0.781977  0.840625       344\n",
      "\n",
      "    accuracy                       0.999488    199364\n",
      "   macro avg   0.954204  0.890921  0.920184    199364\n",
      "weighted avg   0.999467  0.999488  0.999469    199364\n",
      "\n",
      "=========== Stree (SVM Tree) - Test 85,443 samples =============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.999637  0.999918  0.999777     85295\n",
      "           1   0.943548  0.790541  0.860294       148\n",
      "\n",
      "    accuracy                       0.999555     85443\n",
      "   macro avg   0.971593  0.895229  0.930036     85443\n",
      "weighted avg   0.999540  0.999555  0.999536     85443\n",
      "\n",
      "Confusion Matrix in Train\n",
      "[[198993     27]\n",
      " [    75    269]]\n",
      "Confusion Matrix in Test\n",
      "[[85288     7]\n",
      " [   31   117]]\n",
      "************************** AdaBoost model **********************\n",
      "Train Model AdaBoost model took: 46.14 seconds\n",
      "=========== AdaBoost model - Train 199,364 samples =============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.999392  0.999678  0.999535    199020\n",
      "           1   0.777003  0.648256  0.706815       344\n",
      "\n",
      "    accuracy                       0.999072    199364\n",
      "   macro avg   0.888198  0.823967  0.853175    199364\n",
      "weighted avg   0.999008  0.999072  0.999030    199364\n",
      "\n",
      "=========== AdaBoost model - Test 85,443 samples =============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.999484  0.999707  0.999596     85295\n",
      "           1   0.806202  0.702703  0.750903       148\n",
      "\n",
      "    accuracy                       0.999192     85443\n",
      "   macro avg   0.902843  0.851205  0.875249     85443\n",
      "weighted avg   0.999149  0.999192  0.999165     85443\n",
      "\n",
      "Confusion Matrix in Train\n",
      "[[198956     64]\n",
      " [   121    223]]\n",
      "Confusion Matrix in Test\n",
      "[[85270    25]\n",
      " [   44   104]]\n",
      "************************** Bagging model **********************\n",
      "Train Model Bagging model took: 77.73 seconds\n",
      "=========== Bagging model - Train 199,364 samples =============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.999864  1.000000  0.999932    199020\n",
      "           1   1.000000  0.921512  0.959153       344\n",
      "\n",
      "    accuracy                       0.999865    199364\n",
      "   macro avg   0.999932  0.960756  0.979542    199364\n",
      "weighted avg   0.999865  0.999865  0.999862    199364\n",
      "\n",
      "=========== Bagging model - Test 85,443 samples =============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.999637  0.999953  0.999795     85295\n",
      "           1   0.966942  0.790541  0.869888       148\n",
      "\n",
      "    accuracy                       0.999590     85443\n",
      "   macro avg   0.983289  0.895247  0.934842     85443\n",
      "weighted avg   0.999580  0.999590  0.999570     85443\n",
      "\n",
      "Confusion Matrix in Train\n",
      "[[199020      0]\n",
      " [    27    317]]\n",
      "Confusion Matrix in Test\n",
      "[[85291     4]\n",
      " [   31   117]]\n"
     ]
    }
   ],
   "source": [
    "# Train & Test models\n",
    "models = {\n",
    "    'Linear Tree':linear_tree, 'Random Forest': random_forest, 'Stree (SVM Tree)': stree,  \n",
    "    'AdaBoost model': adaboost, 'Bagging model': bagging\n",
    "}\n",
    "\n",
    "best_f1 = 0\n",
    "outcomes = []\n",
    "for name, model in models.items():\n",
    "    f1, time_spent = try_model(name, model)\n",
    "    outcomes.append((name, f1, time_spent))\n",
    "    if f1 > best_f1:\n",
    "        best_model = name\n",
    "        best_time = time_spent\n",
    "        best_f1 = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "**************************************************************************************************************\n*The best f1 model is Random Forest, with a f1 score: 0.8815 in 181.07 seconds with 0.7 samples in train dataset\n**************************************************************************************************************\nModel: Linear Tree\t Time:  15.14 seconds\t f1: 0.7645\nModel: Random Forest\t Time: 181.07 seconds\t f1: 0.8815\nModel: Stree (SVM Tree)\t Time:  36.60 seconds\t f1: 0.8603\nModel: AdaBoost model\t Time:  46.14 seconds\t f1: 0.7509\nModel: Bagging model\t Time:  77.73 seconds\t f1: 0.8699\n"
     ]
    }
   ],
   "source": [
    "print(\"*\"*110)\n",
    "print(f\"*The best f1 model is {best_model}, with a f1 score: {best_f1:.4} in {best_time:.6} seconds with {train_size:,} samples in train dataset\")\n",
    "print(\"*\"*110)\n",
    "for name, f1, time_spent in outcomes:\n",
    "    print(f\"Model: {name}\\t Time: {time_spent:6.2f} seconds\\t f1: {f1:.4}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**************************************************************************************************************\n",
    "*The best f1 model is Random Forest, with a f1 score: 0.8815 in 152.54 seconds with 0.7 samples in train dataset\n",
    "**************************************************************************************************************\n",
    "Model: Linear Tree\t Time:  13.52 seconds\t f1: 0.7645\n",
    "Model: Random Forest\t Time: 152.54 seconds\t f1: 0.8815\n",
    "Model: Stree (SVM Tree)\t Time:  32.55 seconds\t f1: 0.8603\n",
    "Model: AdaBoost model\t Time:  47.34 seconds\t f1: 0.7509\n",
    "Model: Gradient Boost.\t Time: 244.12 seconds\t f1: 0.5259"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "******************************************************************************************************************\n",
    "*The best f1 model is Random Forest, with a f1 score: 0.8815 in 218.966 seconds with 0.7 samples in train dataset\n",
    "******************************************************************************************************************\n",
    "Model: Linear Tree       Time:  23.05 seconds\t f1: 0.7645\n",
    "Model: Random Forest\t Time: 218.97 seconds\t f1: 0.8815\n",
    "Model: Stree (SVM Tree)\t Time:  49.45 seconds\t f1: 0.8603\n",
    "Model: AdaBoost model\t Time:  73.83 seconds\t f1: 0.7509\n",
    "Model: Neural Network\t Time:  25.47 seconds\t f1: 0.8328\n",
    "Model: Bagging model\t Time:  77.93 seconds\t f1: 0.8699\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'C': 0.01,\n",
       " 'criterion': 'entropy',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'linear',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_iter': 1000.0,\n",
       " 'min_samples_split': 0,\n",
       " 'random_state': 2020,\n",
       " 'split_criteria': 'impurity',\n",
       " 'splitter': 'random',\n",
       " 'tol': 0.0001}"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "stree.get_params()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.8.4 64-bit ('general': venv)",
   "language": "python",
   "name": "python38464bitgeneralvenv77203c0a6afd4428bd66253ef62753dc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "392px",
    "left": "1518px",
    "right": "20px",
    "top": "40px",
    "width": "392px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}