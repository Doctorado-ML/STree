{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from stree import Stree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, y = load_iris(return_X_y=True)\n",
    "#y[y==2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fraud: 0.244% 196\nValid: 99.755% 80234\nX.shape (1196, 28)  y.shape (1196,)\nFraud: 16.472% 197\nValid: 83.528% 999\n"
    }
   ],
   "source": [
    "random_state=1\n",
    "\n",
    "def load_creditcard(n_examples=0):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import random\n",
    "    df = pd.read_csv('data/creditcard.csv')\n",
    "    print(\"Fraud: {0:.3f}% {1}\".format(df.Class[df.Class == 1].count()*100/df.shape[0], df.Class[df.Class == 1].count()))\n",
    "    print(\"Valid: {0:.3f}% {1}\".format(df.Class[df.Class == 0].count()*100/df.shape[0], df.Class[df.Class == 0].count()))\n",
    "    y = df.Class\n",
    "    X = df.drop(['Class', 'Time', 'Amount'], axis=1).values\n",
    "    if n_examples > 0:\n",
    "        # Take first n_examples samples\n",
    "        X = X[:n_examples, :]\n",
    "        y = y[:n_examples, :]\n",
    "    else:\n",
    "        # Take all the positive samples with a number of random negatives\n",
    "        if n_examples < 0:\n",
    "            Xt = X[(y == 1).ravel()]\n",
    "            yt = y[(y == 1).ravel()]\n",
    "            indices = random.sample(range(X.shape[0]), -1 * n_examples)\n",
    "            X = np.append(Xt, X[indices], axis=0)\n",
    "            y = np.append(yt, y[indices], axis=0)\n",
    "    print(\"X.shape\", X.shape, \" y.shape\", y.shape)\n",
    "    print(\"Fraud: {0:.3f}% {1}\".format(len(y[y == 1])*100/X.shape[0], len(y[y == 1])))\n",
    "    print(\"Valid: {0:.3f}% {1}\".format(len(y[y == 0]) * 100 / X.shape[0], len(y[y == 0])))\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=random_state, stratify=y)\n",
    "    return Xtrain, Xtest, ytrain, ytest\n",
    "\n",
    "# data = load_creditcard(-5000) # Take all true samples + 5000 of the others\n",
    "# data = load_creditcard(5000)  # Take the first 5000 samples\n",
    "data = load_creditcard(-1000) # Take all the samples\n",
    "\n",
    "Xtrain = data[0]\n",
    "Xtest = data[1]\n",
    "ytrain = data[2]\n",
    "ytest = data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "root\nroot - Down - Leaf class=1.0 belief=0.976000 counts=(array([0., 1.]), array([  3, 122]))\nroot - Up - Leaf class=0.0 belief=0.977528 counts=(array([0., 1.]), array([696,  16]))\n\n"
    }
   ],
   "source": [
    "c = Stree(max_depth=2)\n",
    "c.fit(Xtrain, ytrain)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'base_estimator': [DecisionTreeClassifier(max_depth=1), Stree(max_depth=2), Stree(max_depth=3)],\n",
    "parameters = {\n",
    "    'base_estimator': [LinearSVC(), Stree(max_depth=2), Stree(max_depth=3)],\n",
    "    'n_estimators': [20, 50, 100, 150],\n",
    "    'learning_rate': [.5, 1, 1.5] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters = {\n",
    "#    'base_estimator': [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=5), Stree(), Stree(C=.1), Stree(C=.01), Stree(C=3)],\n",
    "#    'n_estimators': [20, 50, 100, 150],\n",
    "#    'learning_rate': [.5, 1, 1.5]           \n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(X: numpy.ndarray, y: numpy.ndarray, sample_weight: <built-in function array> = None) -> 'Stree'\n"
    }
   ],
   "source": [
    "from inspect import signature\n",
    "print(signature(c.fit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.validation import _check_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.3s\n[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.3s\n[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.3s\n[Parallel(n_jobs=-1)]: Batch computation too fast (0.1671s.) Setting batch_size=2.\n[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.3s\n[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.4s\n[Parallel(n_jobs=-1)]: Batch computation too fast (0.0413s.) Setting batch_size=4.\n[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:    1.4s\n[Parallel(n_jobs=-1)]: Batch computation too slow (7.7880s.) Setting batch_size=1.\n[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    9.2s\n[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed:   48.9s\n[Parallel(n_jobs=-1)]: Done 140 tasks      | elapsed:  1.0min\n[Parallel(n_jobs=-1)]: Done 161 tasks      | elapsed:  1.3min\n[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  1.6min finished\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(estimator=AdaBoostClassifier(random_state=2020), n_jobs=-1,\n             param_grid={'base_estimator': [LinearSVC(), Stree(max_depth=2),\n                                            Stree(max_depth=3)],\n                         'learning_rate': [0.5, 1, 1.5],\n                         'n_estimators': [20, 50, 100, 150]},\n             return_train_score=True, verbose=10)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "random_state=2020\n",
    "clf = AdaBoostClassifier(random_state=random_state)\n",
    "grid = GridSearchCV(clf, parameters, verbose=10, n_jobs=-1, return_train_score=True)\n",
    "grid.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "AdaBoostClassifier(base_estimator=Stree(max_depth=2), learning_rate=0.5,\n                   n_estimators=150, random_state=2020)\n"
    }
   ],
   "source": [
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoostClassifier(base_estimator=Stree(max_depth=3), learning_rate=0.5,\n",
    "                   n_estimators=20, random_state=2020)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitgeneralvenvfbd0a23e74cf4e778460f5ffc6761f39",
   "display_name": "Python 3.7.6 64-bit ('general': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}