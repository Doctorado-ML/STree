{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Google Colab setup\n",
    "#\n",
    "#import os\n",
    "#os.chdir(\"/content\")\n",
    "#!git clone https://github.com/Doctorado-ML/STree.git\n",
    "#os.chdir(\"/content/STree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from stree import Stree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.isfile('data/creditcard.csv'):\n",
    "    !wget --no-check-certificate --content-disposition http://nube.jccm.es/index.php/s/Zs7SYtZQJ3RQ2H2/download\n",
    "    !tar xzf creditcard.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2020-05-23 19:42:08\n"
    }
   ],
   "source": [
    "print(datetime.date.today(), time.strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv('data/creditcard.csv')\n",
    "df.shape\n",
    "random_state = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fraud: 0.173% 492\nValid: 99.827% 284,315\n"
    }
   ],
   "source": [
    "print(\"Fraud: {0:.3f}% {1}\".format(df.Class[df.Class == 1].count()*100/df.shape[0], df.Class[df.Class == 1].count()))\n",
    "print(\"Valid: {0:.3f}% {1:,}\".format(df.Class[df.Class == 0].count()*100/df.shape[0], df.Class[df.Class == 0].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Amount\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "values = RobustScaler().fit_transform(df.Amount.values.reshape(-1, 1))\n",
    "df['Amount_Scaled'] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "X shape: (284807, 29)\ny shape: (284807,)\n"
    }
   ],
   "source": [
    "# Remove unneeded features\n",
    "y = df.Class.values\n",
    "X = df.drop(['Class', 'Time', 'Amount'], axis=1).values\n",
    "print(f\"X shape: {X.shape}\\ny shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide dataset\n",
    "train_size = .7\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=train_size, shuffle=True, random_state=random_state, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Tree\n",
    "linear_tree = tree.DecisionTreeClassifier(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "random_forest = RandomForestClassifier(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stree\n",
    "stree = Stree(random_state=random_state, C=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost\n",
    "adaboost = AdaBoostClassifier(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "gradient = GradientBoostingClassifier(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_model(name, model):\n",
    "    print(f\"************************** {name} **********************\")\n",
    "    now = time.time()\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    spent = time.time() - now\n",
    "    print(f\"Train Model {name} took: {spent:.4} seconds\")\n",
    "    predict = model.predict(Xtrain)\n",
    "    predictt = model.predict(Xtest)\n",
    "    print(f\"=========== {name} - Train {Xtrain.shape[0]:,} samples =============\",)\n",
    "    print(classification_report(ytrain, predict, digits=6))\n",
    "    print(f\"=========== {name} - Test {Xtest.shape[0]:,} samples =============\")\n",
    "    print(classification_report(ytest, predictt, digits=6))\n",
    "    print(\"Confusion Matrix in Train\")\n",
    "    print(confusion_matrix(ytrain, predict))\n",
    "    print(\"Confusion Matrix in Test\")\n",
    "    print(confusion_matrix(ytest, predictt))\n",
    "    return f1_score(ytest, predictt), spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "************************** Linear Tree **********************\nTrain Model Linear Tree took: 16.99 seconds\n=========== Linear Tree - Train 199,364 samples =============\n              precision    recall  f1-score   support\n\n           0   1.000000  1.000000  1.000000    199020\n           1   1.000000  1.000000  1.000000       344\n\n    accuracy                       1.000000    199364\n   macro avg   1.000000  1.000000  1.000000    199364\nweighted avg   1.000000  1.000000  1.000000    199364\n\n=========== Linear Tree - Test 85,443 samples =============\n              precision    recall  f1-score   support\n\n           0   0.999578  0.999613  0.999596     85295\n           1   0.772414  0.756757  0.764505       148\n\n    accuracy                       0.999192     85443\n   macro avg   0.885996  0.878185  0.882050     85443\nweighted avg   0.999184  0.999192  0.999188     85443\n\nConfusion Matrix in Train\n[[199020      0]\n [     0    344]]\nConfusion Matrix in Test\n[[85262    33]\n [   36   112]]\n************************** Random Forest **********************\nTrain Model Random Forest took: 175.7 seconds\n=========== Random Forest - Train 199,364 samples =============\n              precision    recall  f1-score   support\n\n           0   1.000000  1.000000  1.000000    199020\n           1   1.000000  1.000000  1.000000       344\n\n    accuracy                       1.000000    199364\n   macro avg   1.000000  1.000000  1.000000    199364\nweighted avg   1.000000  1.000000  1.000000    199364\n\n=========== Random Forest - Test 85,443 samples =============\n              precision    recall  f1-score   support\n\n           0   0.999660  0.999965  0.999812     85295\n           1   0.975410  0.804054  0.881481       148\n\n    accuracy                       0.999625     85443\n   macro avg   0.987535  0.902009  0.940647     85443\nweighted avg   0.999618  0.999625  0.999607     85443\n\nConfusion Matrix in Train\n[[199020      0]\n [     0    344]]\nConfusion Matrix in Test\n[[85292     3]\n [   29   119]]\n************************** Stree (SVM Tree) **********************\nTrain Model Stree (SVM Tree) took: 39.64 seconds\n=========== Stree (SVM Tree) - Train 199,364 samples =============\n              precision    recall  f1-score   support\n\n           0   0.999613  0.999869  0.999741    199020\n           1   0.911263  0.776163  0.838305       344\n\n    accuracy                       0.999483    199364\n   macro avg   0.955438  0.888016  0.919023    199364\nweighted avg   0.999461  0.999483  0.999463    199364\n\n=========== Stree (SVM Tree) - Test 85,443 samples =============\n              precision    recall  f1-score   support\n\n           0   0.999613  0.999883  0.999748     85295\n           1   0.920000  0.777027  0.842491       148\n\n    accuracy                       0.999497     85443\n   macro avg   0.959807  0.888455  0.921119     85443\nweighted avg   0.999475  0.999497  0.999476     85443\n\nConfusion Matrix in Train\n[[198994     26]\n [    77    267]]\nConfusion Matrix in Test\n[[85285    10]\n [   33   115]]\n************************** AdaBoost model **********************\nTrain Model AdaBoost model took: 48.29 seconds\n=========== AdaBoost model - Train 199,364 samples =============\n              precision    recall  f1-score   support\n\n           0   0.999392  0.999678  0.999535    199020\n           1   0.777003  0.648256  0.706815       344\n\n    accuracy                       0.999072    199364\n   macro avg   0.888198  0.823967  0.853175    199364\nweighted avg   0.999008  0.999072  0.999030    199364\n\n=========== AdaBoost model - Test 85,443 samples =============\n              precision    recall  f1-score   support\n\n           0   0.999484  0.999707  0.999596     85295\n           1   0.806202  0.702703  0.750903       148\n\n    accuracy                       0.999192     85443\n   macro avg   0.902843  0.851205  0.875249     85443\nweighted avg   0.999149  0.999192  0.999165     85443\n\nConfusion Matrix in Train\n[[198956     64]\n [   121    223]]\nConfusion Matrix in Test\n[[85270    25]\n [   44   104]]\n************************** Gradient Boost. **********************\nTrain Model Gradient Boost. took: 251.6 seconds\n=========== Gradient Boost. - Train 199,364 samples =============\n              precision    recall  f1-score   support\n\n           0   0.999096  0.999854  0.999475    199020\n           1   0.849741  0.476744  0.610801       344\n\n    accuracy                       0.998952    199364\n   macro avg   0.924419  0.738299  0.805138    199364\nweighted avg   0.998839  0.998952  0.998804    199364\n\n=========== Gradient Boost. - Test 85,443 samples =============\n              precision    recall  f1-score   support\n\n           0   0.998981  0.999730  0.999355     85295\n           1   0.726190  0.412162  0.525862       148\n\n    accuracy                       0.998713     85443\n   macro avg   0.862586  0.705946  0.762609     85443\nweighted avg   0.998508  0.998713  0.998535     85443\n\nConfusion Matrix in Train\n[[198991     29]\n [   180    164]]\nConfusion Matrix in Test\n[[85272    23]\n [   87    61]]\n"
    }
   ],
   "source": [
    "# Train & Test models\n",
    "models = {\n",
    "    'Linear Tree':linear_tree, 'Random Forest': random_forest, 'Stree (SVM Tree)': stree,  \n",
    "    'AdaBoost model': adaboost, 'Gradient Boost.': gradient\n",
    "}\n",
    "\n",
    "best_f1 = 0\n",
    "outcomes = []\n",
    "for name, model in models.items():\n",
    "    f1, time_spent = try_model(name, model)\n",
    "    outcomes.append((name, f1, time_spent))\n",
    "    if f1 > best_f1:\n",
    "        best_model = name\n",
    "        best_time = time_spent\n",
    "        best_f1 = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "**************************************************************************************************************\n*The best f1 model is Random Forest, with a f1 score: 0.8815 in 175.717 seconds with 0.7 samples in train dataset\n**************************************************************************************************************\nModel: Linear Tree\t Time:  16.99 seconds\t f1: 0.7645\nModel: Random Forest\t Time: 175.72 seconds\t f1: 0.8815\nModel: Stree (SVM Tree)\t Time:  39.64 seconds\t f1: 0.8425\nModel: AdaBoost model\t Time:  48.29 seconds\t f1: 0.7509\nModel: Gradient Boost.\t Time: 251.58 seconds\t f1: 0.5259\n"
    }
   ],
   "source": [
    "print(\"*\"*110)\n",
    "print(f\"*The best f1 model is {best_model}, with a f1 score: {best_f1:.4} in {best_time:.6} seconds with {train_size:,} samples in train dataset\")\n",
    "print(\"*\"*110)\n",
    "for name, f1, time_spent in outcomes:\n",
    "    print(f\"Model: {name}\\t Time: {time_spent:6.2f} seconds\\t f1: {f1:.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "******************************************************************************************************************\n",
    "*The best f1 model is Random Forest, with a f1 score: 0.8815 in 218.966 seconds with 0.7 samples in train dataset\n",
    "******************************************************************************************************************\n",
    "Model: Linear Tree       Time:  23.05 seconds\t f1: 0.7645\n",
    "Model: Random Forest\t Time: 218.97 seconds\t f1: 0.8815\n",
    "Model: Stree (SVM Tree)\t Time:  49.45 seconds\t f1: 0.8467\n",
    "Model: AdaBoost model\t Time:  73.83 seconds\t f1: 0.7509\n",
    "Model: Gradient Boost.\t Time: 388.69 seconds\t f1: 0.5259\n",
    "Model: Neural Network\t Time:  25.47 seconds\t f1: 0.8328\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "392px",
    "left": "1518px",
    "right": "20px",
    "top": "40px",
    "width": "392px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}